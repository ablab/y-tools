{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import gammaln, betaln, psi\n",
    "from scipy.optimize import check_grad\n",
    "from scipy.optimize import minimize, approx_fprime\n",
    "from math_special_functions import multibetaln, dibetaln, dimultibetaln\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ShmKmerLikelihoodOLD:\n",
    "    def __init__(self, sample, nonmutated_ind, check_gradient=False, number_of_tests=None):\n",
    "        self.full_sample = sample\n",
    "        self.mutated_sample = np.delete(sample, nonmutated_ind, 1)\n",
    "        self.nonmutated_ind = nonmutated_ind\n",
    "\n",
    "        self.n_all = np.sum(self.full_sample, axis=1)\n",
    "        self.n_mutated = np.sum(self.mutated_sample, axis=1)\n",
    "\n",
    "        if check_gradient:\n",
    "            if number_of_tests is None:\n",
    "                print(\"Supply number of tests for check_gradient.\")\n",
    "            else:\n",
    "                self.__check_gradient(number_of_tests)\n",
    "\n",
    "    def likelihood(self, beta_shape1, beta_shape2, dir_lambda):\n",
    "        result_p11 = betaln(beta_shape1 + self.n_mutated,\n",
    "                            beta_shape2 + self.n_all - self.n_mutated)\n",
    "        result_p12 = betaln(beta_shape1, beta_shape2)\n",
    "        \n",
    "        result_p21 = multibetaln(self.mutated_sample + dir_lambda, 1)\n",
    "        result_p22 = multibetaln(dir_lambda)\n",
    "            \n",
    "        return np.sum(result_p11 - result_p12 + result_p21 - result_p22)\n",
    "\n",
    "    def gradient(self, beta_shape1, beta_shape2, dir_lambda):\n",
    "        N = self.full_sample.shape[0]\n",
    "        result_p11 = np.sum(dibetaln(beta_shape1 + self.n_mutated,\n",
    "                           beta_shape2 + self.n_all - self.n_mutated), 0)\n",
    "        result_p12 = dibetaln(beta_shape1, beta_shape2).flatten() * N\n",
    "\n",
    "        result_p21 = np.sum(dimultibetaln(self.mutated_sample + dir_lambda), 0)\n",
    "        result_p22 = dimultibetaln(dir_lambda) * N\n",
    "\n",
    "        return np.concatenate((result_p11 - result_p12,\n",
    "                               result_p21 - result_p22))\n",
    "\n",
    "    def __check_gradient(self, number_of_tests=None):\n",
    "        cglikelihood = (lambda x: self.likelihood(beta_shape1=x[0],\n",
    "                                                  beta_shape2=x[1],\n",
    "                                                  dir_lambda=x[2:]))\n",
    "        cggrad = (lambda x: self.gradient(beta_shape1=x[0],\n",
    "                                          beta_shape2=x[1],\n",
    "                                          dir_lambda=x[2:]))\n",
    "        if number_of_tests is not None:\n",
    "            for i in xrange(number_of_tests):\n",
    "                point = np.random.exponential(size=5, scale=10)\n",
    "                print(check_grad(cglikelihood, cggrad, x0=point))\n",
    "        if x is not None:\n",
    "            print(check_grad(cglikelihood, cggrad, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ShmKmerLikelihoodOptimizatorOLD:\n",
    "    def __init__(self, shm_kmer_likelihood, x0=None, bounds=None, method='L-BFGS-B'):\n",
    "        if x0 is None:\n",
    "            self.x0 = self.__get_start_point(shm_kmer_likelihood)\n",
    "        if bounds is None:\n",
    "            self.bounds=((0, None),) * (2 + shm_kmer_likelihood.mutated_sample.shape[1])\n",
    "        self.method=method\n",
    "        self.lkhd = (lambda x: -shm_kmer_likelihood.likelihood(beta_shape1=x[0],\n",
    "                                                               beta_shape2=x[1],\n",
    "                                                               dir_lambda=x[2:]))\n",
    "        self.grad = (lambda x: -shm_kmer_likelihood.gradient(beta_shape1=x[0],\n",
    "                                                             beta_shape2=x[1],\n",
    "                                                             dir_lambda=x[2:]))\n",
    "        \n",
    "    def __get_start_point(self, shm_kmer_likelihood, scale_beta=1, scale_dir=1):\n",
    "        beta_shape1 = np.mean(1 - shm_kmer_likelihood.full_sample[:,shm_kmer_likelihood.nonmutated_ind] / \\\n",
    "                              np.sum(shm_kmer_likelihood.full_sample, axis=1, dtype=float))\n",
    "        beta_shape2 = 1 - beta_shape1\n",
    "        beta_shape1 *= scale_beta\n",
    "        beta_shape2 *= scale_beta\n",
    "        \n",
    "        scaled_mutated_sample = (shm_kmer_likelihood.mutated_sample.T / \\\n",
    "                                 np.sum(shm_kmer_likelihood.mutated_sample, axis=1, dtype=float)).T\n",
    "        dir_lambda = np.mean(scaled_mutated_sample, axis=0, dtype=float)\n",
    "        dir_lambda *= scale_dir\n",
    "        return np.concatenate([np.array([beta_shape1, beta_shape2]), dir_lambda])\n",
    "    \n",
    "    def maximize(self):\n",
    "        minimize_result = minimize(fun=self.lkhd,\n",
    "                                   x0=self.x0,\n",
    "                                   bounds=self.bounds,\n",
    "                                   method=self.method,\n",
    "                                   jac=self.grad)\n",
    "        return minimize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shm_kmer_likelihood_optimize import ShmKmerLikelihood, ShmKmerLikelihoodOptimizator\n",
    "from generate_test_sample import generate_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = generate_sample(sample_size=1000,\n",
    "                         number_samples=10,\n",
    "                         real_beta_shape1=5,\n",
    "                         real_beta_shape2=15,\n",
    "                         real_dir_lambda=[4,5,6],\n",
    "                         nonmutated_ind=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[825,  43,  88,  44],\n",
       "       [825,  66,  38,  71],\n",
       "       [681, 114,  85, 120],\n",
       "       [758,  46, 124,  72],\n",
       "       [767,  75,  99,  59],\n",
       "       [856,  28,  86,  30],\n",
       "       [775,  83,  36, 106],\n",
       "       [665,  28, 193, 114],\n",
       "       [736,  49, 103, 112],\n",
       "       [626, 100, 124, 150]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lkho = ShmKmerLikelihood(sample, 0)\n",
    "lkho_old = ShmKmerLikelihoodOLD(sample, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lkhoo = ShmKmerLikelihoodOptimizator(lkho)\n",
    "lkhoo_old = ShmKmerLikelihoodOptimizatorOLD(lkho_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      fun: 5492.5847881541868\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -2.85342285e-06,   6.81973513e-07])\n",
       "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 17\n",
       "      nit: 16\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  9.3882882 ,  28.37167499]),\n",
       "       fun: 2594.8816967749867\n",
       " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -8.17272631e-06,  -1.57742297e-05,   4.02029054e-05])\n",
       "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 15\n",
       "      nit: 14\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 4.68960327,  6.96849514,  6.34373814]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lkhoo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 8087.4664860037483\n",
       " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ -6.43493214e-04,   2.92009344e-04,  -4.78013947e-06,\n",
       "         3.24464620e-04,  -4.54507542e-04])\n",
       "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 24\n",
       "      nit: 21\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([  9.39242926,  28.38732679,   4.68924881,   6.96818506,   6.34292881])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lkhoo_old.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
