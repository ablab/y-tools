{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import gammaln, betaln, psi\n",
    "from scipy.optimize import check_grad\n",
    "from scipy.optimize import minimize, approx_fprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LikelihoodOptimizator:\n",
    "    def __init__(self, sample, nonmutated_ind):\n",
    "        self.full_sample = sample\n",
    "        self.mutated_sample = np.delete(sample, nonmutated_ind, 1)\n",
    "        self.nonmutated_ind = nonmutated_ind\n",
    "        self.n_all = np.sum(self.full_sample, axis=1)\n",
    "        self.n_mutated = np.sum(self.mutated_sample, axis=1)\n",
    "        \n",
    "\n",
    "    def likelihood(self, beta_shape1, beta_shape2, dir_lambda):\n",
    "        multibetaln = (lambda x, axis=None:\n",
    "                       np.sum(gammaln(x), axis=axis) - gammaln(np.sum(x, axis=axis)))\n",
    "        result_p1 = betaln(beta_shape1 + self.n_mutated,\n",
    "                           beta_shape2 + self.n_all - self.n_mutated) - \\\n",
    "                    betaln(beta_shape1, beta_shape2) #* self.full_sample.shape[0]\n",
    "        result_p2 = multibetaln(self.mutated_sample + dir_lambda, 1) - \\\n",
    "                    multibetaln(dir_lambda) #* self.full_sample.shape[0]\n",
    "            \n",
    "        return np.sum(result_p1 + result_p2)\n",
    "\n",
    "    def gradient(self, beta_shape1, beta_shape2, dir_lambda):\n",
    "        dibetaln = (lambda x, y: (np.vstack((psi(x), psi(y))) - psi(x + y)).T)\n",
    "        dimultibetaln = (lambda x: (psi(x).T - \\\n",
    "                                    (psi(np.sum(x, axis=1)) if len(x.shape) == 2 else psi(np.sum(x)))).T)\n",
    "        \n",
    "        result_p1 = np.sum(dibetaln(beta_shape1 + self.n_mutated,\n",
    "                           beta_shape2 + self.n_all - self.n_mutated), 0) - \\\n",
    "                    dibetaln(beta_shape1, beta_shape2).flatten() * self.full_sample.shape[0]\n",
    "        result_p2 = np.sum(dimultibetaln(self.mutated_sample + dir_lambda), 0) - \\\n",
    "                    dimultibetaln(dir_lambda) * self.full_sample.shape[0]\n",
    "        return np.concatenate((result_p1, result_p2))\n",
    "    \n",
    "    def check_gradient(self, number_of_tests=None, x=None):\n",
    "        cglikelihood = (lambda x: self.likelihood(beta_shape1=x[0], beta_shape2=x[1], dir_lambda=x[2:]))\n",
    "        cggrad       = (lambda x: self.gradient(  beta_shape1=x[0], beta_shape2=x[1], dir_lambda=x[2:]))\n",
    "        if number_of_tests is not None:\n",
    "            for i in xrange(number_of_tests):\n",
    "                point = np.random.exponential(size=5, scale=10)\n",
    "                print(approx_fprime(point, cglikelihood, 1e-5))\n",
    "                print(cggrad(point))\n",
    "                print(check_grad(cglikelihood, cggrad, x0=point))\n",
    "        if x is not None:\n",
    "            print(check_grad(cglikelihood, cggrad, x))\n",
    "            \n",
    "    def maximize(self, x0 = [2, 1, 1, 1, 1], bounds=None, method='L-BFGS-B', disp=False):\n",
    "        if bounds is None:\n",
    "            bounds=((0, None),) * (2 + self.mutated_sample.shape[1])\n",
    "        lkhd = (lambda x: -self.likelihood(beta_shape1=x[0], beta_shape2=x[1], dir_lambda=x[2:]))\n",
    "        grad = (lambda x: -self.gradient(  beta_shape1=x[0], beta_shape2=x[1], dir_lambda=x[2:]))\n",
    "        \n",
    "        minimize_result = minimize(fun=lkhd, x0=x0, bounds=bounds, method=method, jac=grad, options={'disp': disp})\n",
    "        print(minimize_result)\n",
    "        return minimize_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(sample_size, number_samples,\n",
    "                    real_beta_shape1, real_beta_shape2, real_dir_lambda,\n",
    "                    nonmutated_ind):\n",
    "    mutation_bin_prob = np.random.beta(real_beta_shape1, real_beta_shape2, size=number_samples)\n",
    "    is_mutated = np.random.binomial(sample_size, p=mutation_bin_prob, size=number_samples)\n",
    "\n",
    "    mutation_dir_probs = np.random.dirichlet(real_dir_lambda, size=number_samples)\n",
    "    sample = []\n",
    "    for n, pvals in zip(is_mutated, mutation_dir_probs):\n",
    "        sample.append(np.random.multinomial(n=n, pvals=pvals, size=1))\n",
    "    sample = np.array(sample).reshape((number_samples, len(real_dir_lambda)))\n",
    "    final_sample = np.insert(sample, nonmutated_ind, sample_size - is_mutated, axis=1)\n",
    "    return final_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_nonmutated_ind = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = generate_sample(sample_size=10000, number_samples=10000, nonmutated_ind=sample_nonmutated_ind,\n",
    "                         real_beta_shape1=3, real_beta_shape2=2, real_dir_lambda=np.array([10, 12, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lkho = LikelihoodOptimizator(sample, sample_nonmutated_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 122238457.21803215\n",
      " hess_inv: <5x5 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ -4.19037267,  16.30472631,   7.28750333,  -5.60050776,   0.06055079])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 13\n",
      "      nit: 12\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  2.99826911,   2.00749849,  10.01842958,  12.03892569,  13.05987628])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2.99826911,   2.00749849,  10.01842958,  12.03892569,  13.05987628])"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lkho.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-32151.49231255  98010.20883024  93427.7696535  -42227.7668491\n",
      "  87704.39699292]\n",
      "[-32151.49168379  98010.35618963  93427.90841002 -42227.76839328\n",
      "  87704.49135788]\n",
      "0.331103143776\n"
     ]
    }
   ],
   "source": [
    "#lkho.gradient(1, 1, [1,1,1])\n",
    "lkho.check_gradient(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dibetaln_check = (lambda x: (np.vstack((psi(x[0]), psi(x[1]))) - psi(x[0] + x[1])).T.flatten())\n",
    "betaln_check = (lambda x: betaln(x[0], x[1]))\n",
    "for i in xrange(20):\n",
    "    point = np.random.exponential(size=2, scale=20)\n",
    "    #print(check_grad(betaln_check, dibetaln_check, x0=point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.45228154, -8.48872719])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dibetaln_check(np.array([3 + lkho.n_mutated, 2 + lkho.n_all - lkho.n_mutated])), axis=0) #- np.array([[1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50289408, -0.92843373]])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dibetaln_check(np.array([3 + lkho.n_mutated[0], 2 + lkho.n_all[0] - lkho.n_mutated[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "multibetaln_check = (lambda x: np.sum(gammaln(x)) - gammaln(np.sum(x)))\n",
    "dimultibetaln_check = (lambda x: (psi(x).T - \\\n",
    "                                    (psi(np.sum(x, axis=1)) if len(x.shape) == 2 else psi(np.sum(x)))).T)\n",
    "               \n",
    "for i in xrange(20):\n",
    "    point = np.random.exponential(size=8, scale=20)\n",
    "    #print(check_grad(multibetaln_check, dimultibetaln_check, x0=point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.37990723, -1.3334644 , -0.72453307],\n",
       "       [-1.56335309, -0.82497894, -1.0436484 ],\n",
       "       [-1.01971286, -1.1922117 , -1.09205709],\n",
       "       [-1.43430089, -1.29107821, -0.72024073],\n",
       "       [-1.40485115, -0.74200365, -1.27899467],\n",
       "       [-1.26483513, -1.013723  , -1.03635359],\n",
       "       [-1.43823557, -1.16974229, -0.79402478],\n",
       "       [-1.22221262, -1.21327358, -0.89628067],\n",
       "       [-1.03554123, -1.1805062 , -1.08559236],\n",
       "       [-1.081951  , -1.08678193, -1.12845463]])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimultibetaln_check(lkho.mutated_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37990723, -1.3334644 , -0.72453307])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimultibetaln_check(lkho.mutated_sample[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
